<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>3D Hand Hologram Tracker</title>
    <style>
        body { margin: 0; overflow: hidden; background-color: #000; font-family: sans-serif; }
        #canvas-container { width: 100vw; height: 100vh; position: absolute; top: 0; left: 0; z-index: 1; }
        
        /* Video feed element for tracking (can be hidden or shown) */
        #input_video { 
            position: absolute; bottom: 20px; right: 20px; 
            width: 240px; height: 180px; z-index: 2; 
            transform: scaleX(-1); /* Mirror the video feed */
            opacity: 0.1; /* Make it nearly invisible, or set to 0 to hide completely */
        }

        #ui-layer {
            position: absolute; top: 20px; left: 50%; transform: translateX(-50%);
            z-index: 5; color: white; background: rgba(0, 0, 0, 0.7);
            padding: 10px 20px; border-radius: 8px; font-size: 1.1rem;
            text-align: center;
        }
        .key { color: #00ffff; }
        .alert { color: #ffcc00; }
    </style>
    
    <script src="https://cdnjs.cloudflare.com/ajax/libs/three.js/r128/three.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/camera_utils/camera_utils.js" crossorigin="anonymous"></script>
    <script src="https://cdn.jsdelivr.net/npm/@mediapipe/hands/hands.js" crossorigin="anonymous"></script>
</head>
<body>

    <div id="ui-layer">
        <div class="alert">3D Hand Hologram</div>
        <div id="status">Waiting for camera...</div>
    </div>

    <video id="input_video" autoplay playsinline></video>
    
    <div id="canvas-container"></div>

<script>
    // ==========================================
    // 1. THREE.JS SETUP
    // ==========================================
    const container = document.getElementById('canvas-container');
    const scene = new THREE.Scene();

    const camera = new THREE.PerspectiveCamera(75, window.innerWidth / window.innerHeight, 0.1, 1000);
    camera.position.z = 20; // Position camera far enough to see the hand

    const renderer = new THREE.WebGLRenderer({ antialias: true, alpha: true });
    renderer.setSize(window.innerWidth, window.innerHeight);
    container.appendChild(renderer.domElement);

    // Add a subtle ambient light and a directional light for better visibility
    scene.add(new THREE.AmbientLight(0x404040));
    const directionalLight = new THREE.DirectionalLight(0xffffff, 1);
    directionalLight.position.set(0, 10, 10);
    scene.add(directionalLight);

    // --- Hand Object Initialization ---
    const HAND_GROUP = new THREE.Group();
    scene.add(HAND_GROUP);

    const SPHERE_COUNT = 21;
    const sphere_size = 0.5;
    const spheres = []; // To hold the joint spheres
    const lines = [];   // To hold the bone lines

    // Material for a glowing, holographic look
    const sphereMaterial = new THREE.MeshPhongMaterial({
        color: 0x00ffff,
        emissive: 0x00ffff,
        emissiveIntensity: 0.5,
        shininess: 100
    });
    const lineMaterial = new THREE.LineBasicMaterial({
        color: 0x00ffaa,
        linewidth: 3 // Note: linewidth is often ignored by WebGLRenderer
    });

    // Create 21 spheres for the joints (landmarks)
    for (let i = 0; i < SPHERE_COUNT; i++) {
        const sphereGeo = new THREE.SphereGeometry(sphere_size, 8, 8);
        const sphere = new THREE.Mesh(sphereGeo, sphereMaterial.clone());
        spheres.push(sphere);
        HAND_GROUP.add(sphere);
    }

    // Define the bone connections based on MediaPipe hand landmarks (21 points)
    // Each pair is [start_index, end_index]
    const CONNECTIONS = [
        [0, 1], [1, 2], [2, 3], [3, 4],       // Thumb
        [0, 5], [5, 6], [6, 7], [7, 8],       // Index
        [9, 10], [10, 11], [11, 12],          // Middle
        [0, 9], [9, 13], [13, 14], [14, 15], [15, 16], // Middle-Ring
        [0, 17], [17, 18], [18, 19], [19, 20] // Pinky
    ];

    // Create lines for the bones
    for (const [start, end] of CONNECTIONS) {
        // Line will be updated every frame, so we use an empty geometry initially
        const geometry = new THREE.BufferGeometry();
        const line = new THREE.Line(geometry, lineMaterial);
        lines.push({ start: start, end: end, object: line });
        HAND_GROUP.add(line);
    }

    // ==========================================
    // 2. COORDINATE MAPPING
    // ==========================================

    /* * MediaPipe coordinates are normalized (0 to 1) relative to the video feed.
     * We need to map them to world space, considering:
     * 1. X-axis reversal (for mirroring)
     * 2. Scaling (to make the hand the right size in the 3D world)
     * 3. Centering (so the hand is near the origin)
    */

    const SCALE_FACTOR = 40; // Adjust this to change the hand's size
    const cameraLookAt = new THREE.Vector3(0, 0, 0);

    function mapMediaPipeToThreeJS(landmark) {
        // x: 1 - landmark.x reverses the X-axis for mirroring
        // y: (1 - landmark.y) maps the Y axis (0=top in MediaPipe, 0=center in Three.js)
        // z: landmark.z is the depth, often negative (away from camera)
        
        const x = (1 - landmark.x) * SCALE_FACTOR - (SCALE_FACTOR / 2); // Reverse X and center
        const y = (1 - landmark.y) * SCALE_FACTOR - (SCALE_FACTOR / 2); // Reverse Y and center
        const z = landmark.z * SCALE_FACTOR; // Use Z as depth

        return new THREE.Vector3(x, y, z);
    }

    // ==========================================
    // 3. MEDIAPIPE HAND TRACKING & UPDATE
    // ==========================================
    const videoElement = document.getElementById('input_video');
    const statusDiv = document.getElementById('status');
    let landmarkPositions = []; // Array to store calculated 3D positions

    function onResults(results) {
        if (results.multiHandLandmarks && results.multiHandLandmarks.length > 0) {
            statusDiv.innerHTML = `<span class="alert">Tracking Hand: ${results.multiHandedness[0].label}</span>`;
            
            const handLandmarks = results.multiHandLandmarks[0];
            landmarkPositions = [];
            
            // 1. Convert all 21 normalized landmarks to Three.js coordinates
            for (let i = 0; i < SPHERE_COUNT; i++) {
                const vec3 = mapMediaPipeToThreeJS(handLandmarks[i]);
                landmarkPositions.push(vec3);
            }

            // 2. Update the position of all spheres
            for (let i = 0; i < SPHERE_COUNT; i++) {
                spheres[i].position.copy(landmarkPositions[i]);
                // Depth cueing: Make distant spheres slightly smaller
                // Z is usually negative (closer to camera)
                spheres[i].scale.setScalar(1 - landmarkPositions[i].z / 40); 
            }

            // 3. Update the lines (bones)
            for (const connection of lines) {
                const startPos = landmarkPositions[connection.start];
                const endPos = landmarkPositions[connection.end];

                const points = [startPos, endPos];
                connection.object.geometry.setFromPoints(points);
            }
        
        } else {
            statusDiv.innerHTML = "No hand detected. <span class='key'>Ensure your hand is clearly visible.</span>";
            // Hide the hand when not detected
            HAND_GROUP.visible = false;
        }

        HAND_GROUP.visible = landmarkPositions.length > 0;
    }

    const hands = new Hands({locateFile: (file) => `https://cdn.jsdelivr.net/npm/@mediapipe/hands/${file}`});
    hands.setOptions({ 
        maxNumHands: 1, // Only track one hand for simplicity
        modelComplexity: 1, 
        minDetectionConfidence: 0.7, 
        minTrackingConfidence: 0.7 
    });
    hands.onResults(onResults);

    // Setup the camera feed for MediaPipe
    const cameraUtils = new Camera(videoElement, {
        onFrame: async () => { await hands.send({image: videoElement}); },
        width: 640, height: 480 // Higher resolution for better tracking
    });
    cameraUtils.start().then(() => {
        statusDiv.innerText = "Camera Active. Show your hand!";
    }).catch(err => {
        statusDiv.innerHTML = `<span class="alert">Error: ${err.name}. Check camera permissions.</span>`;
    });

    // ==========================================
    // 4. ANIMATION LOOP
    // ==========================================

    function animate() {
        requestAnimationFrame(animate);

        // Optional: Rotate the hand group slightly to simulate hologram effect
        // HAND_GROUP.rotation.y += 0.005; 

        renderer.render(scene, camera);
    }
    animate();

    // Resize Handler
    window.addEventListener('resize', () => {
        camera.aspect = window.innerWidth / window.innerHeight;
        camera.updateProjectionMatrix();
        renderer.setSize(window.innerWidth, window.innerHeight);
    });

</script>
</body>
</html>